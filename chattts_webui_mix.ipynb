{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "> ğŸŒŸ å¦‚æœä½ è§‰å¾— ChatTTS å’Œ ChatTTS_colab é¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·è®¿é—®ä»¥ä¸‹é“¾æ¥ç»™å®ƒä»¬ç‚¹ä¸ªæ˜Ÿæ˜Ÿå§ï¼ğŸŒŸ\n",
        "\n",
        "- [ChatTTS é¡¹ç›®](https://github.com/2noise/ChatTTS)\n",
        "\n",
        "- [ChatTTS_colab é¡¹ç›®](https://github.com/6drf21e/ChatTTS_colab)\n",
        "\n",
        "æ„Ÿè°¢ä½ çš„æ”¯æŒï¼\n",
        "\n",
        "# è¿è¡Œæ–¹æ³•\n",
        "\n",
        "- ç‚¹å‡»èœå•æ çš„--ä»£ç æ‰§è¡Œç¨‹åº--å…¨éƒ¨è¿è¡Œå³å¯\n",
        "- æ‰§è¡Œååœ¨ä¸‹æ–¹çš„æ—¥å¿—ä¸­æ‰¾åˆ°ç±»ä¼¼\n",
        "\n",
        "  Running on public URL: https://**************.gradio.live  <-è¿™ä¸ªå°±æ˜¯å¯ä»¥è®¿é—®çš„å…¬ç½‘åœ°å€\n",
        "\n",
        "å®‰è£…åŒ…çš„æ—¶å€™æç¤ºè¦é‡å¯ è¯·ç‚¹**\"å¦\"**"
      ],
      "metadata": {
        "id": "Xo3k5XsTzWK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -q https://github.com/6drf21e/ChatTTS_colab\n",
        "%cd ChatTTS_colab\n",
        "!git clone -q https://github.com/2noise/ChatTTS\n",
        "%cd ChatTTS\n",
        "!git checkout -q e6412b1\n",
        "%cd ..\n",
        "!mv ChatTTS abc\n",
        "!mv abc/* /content/ChatTTS_colab/\n",
        "!pip install -q omegaconf vocos vector_quantize_pytorch gradio cn2an pypinyin openai jieba WeTextProcessing python-dotenv\n",
        "# å¯åŠ¨ Gradio æœ‰å…¬ç½‘åœ°å€\n",
        "!python webui_mix.py --share\n"
      ],
      "metadata": {
        "id": "hNDl-5muR77-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daa5cffe-0e10-4a9b-d9db-92adc1cf80c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/ChatTTS_colab\n",
            "/content/ChatTTS_colab/ChatTTS\n",
            "/content/ChatTTS_colab\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.4/47.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.3/62.3 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.1/322.1 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m224.9/224.9 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m834.7/834.7 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.8/154.8 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m106.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "2025-03-10 12:00:20.284509: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741608020.526782    1501 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741608020.593266    1501 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-10 12:00:21.117203: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading ChatTTS model...\n",
            "INFO:ChatTTS.core:Download from HF: https://huggingface.co/2Noise/ChatTTS\n",
            "Fetching 12 files:   0% 0/12 [00:00<?, ?it/s]\n",
            "spk_stat.pt: 100% 4.26k/4.26k [00:00<00:00, 12.5MB/s]\n",
            "\n",
            "DVAE.pt:   0% 0.00/27.7M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Decoder.pt:   0% 0.00/104M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Vocos.pt:   0% 0.00/54.4M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:   0% 0.00/901M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "DVAE_full.pt:   0% 0.00/60.4M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "decoder.yaml: 100% 117/117 [00:00<00:00, 624kB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizer.pt: 100% 337k/337k [00:00<00:00, 5.60MB/s]\n",
            "\n",
            "DVAE.pt:  38% 10.5M/27.7M [00:00<00:00, 70.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "DVAE_full.pt:  17% 10.5M/60.4M [00:00<00:00, 77.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Decoder.pt:  10% 10.5M/104M [00:00<00:01, 62.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:   1% 10.5M/901M [00:00<00:15, 58.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "dvae.yaml: 100% 143/143 [00:00<00:00, 823kB/s]\n",
            "\n",
            "\n",
            "\n",
            "Vocos.pt:  19% 10.5M/54.4M [00:00<00:00, 51.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gpt.yaml: 100% 346/346 [00:00<00:00, 2.13MB/s]\n",
            "\n",
            "DVAE.pt:  76% 21.0M/27.7M [00:00<00:00, 69.7MB/s]\u001b[A\n",
            "\n",
            "Decoder.pt:  20% 21.0M/104M [00:00<00:01, 67.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:   2% 21.0M/901M [00:00<00:12, 72.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "path.yaml: 100% 309/309 [00:00<00:00, 1.32MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "DVAE_full.pt:  35% 21.0M/60.4M [00:00<00:00, 62.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "DVAE.pt: 100% 27.7M/27.7M [00:00<00:00, 60.2MB/s]\n",
            "\n",
            "\n",
            "Fetching 12 files:   8% 1/12 [00:00<00:06,  1.59it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "DVAE_full.pt:  52% 31.5M/60.4M [00:00<00:00, 73.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Vocos.pt:  58% 31.5M/54.4M [00:00<00:00, 60.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "vocos.yaml: 100% 460/460 [00:00<00:00, 2.07MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:   5% 41.9M/901M [00:00<00:10, 78.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Decoder.pt:  40% 41.9M/104M [00:00<00:00, 74.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "DVAE_full.pt:  69% 41.9M/60.4M [00:00<00:00, 69.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Vocos.pt:  77% 41.9M/54.4M [00:00<00:00, 68.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:   6% 52.4M/901M [00:00<00:10, 82.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Vocos.pt:  96% 52.4M/54.4M [00:00<00:00, 76.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Decoder.pt:  61% 62.9M/104M [00:00<00:00, 80.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:   7% 62.9M/901M [00:00<00:10, 80.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Vocos.pt: 100% 54.4M/54.4M [00:00<00:00, 62.3MB/s]\n",
            "DVAE_full.pt: 100% 60.4M/60.4M [00:00<00:00, 68.8MB/s]\n",
            "Fetching 12 files:  17% 2/12 [00:01<00:05,  1.93it/s]\n",
            "\n",
            "Decoder.pt:  71% 73.4M/104M [00:00<00:00, 81.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:   9% 83.9M/901M [00:00<00:08, 96.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Decoder.pt:  91% 94.4M/104M [00:01<00:00, 99.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Decoder.pt: 100% 104M/104M [00:01<00:00, 88.7MB/s] \n",
            "Fetching 12 files:  25% 3/12 [00:01<00:03,  2.50it/s]\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  14% 126M/901M [00:01<00:05, 129MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  17% 157M/901M [00:01<00:04, 159MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  21% 189M/901M [00:01<00:03, 182MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  23% 210M/901M [00:01<00:03, 188MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  27% 241M/901M [00:01<00:03, 199MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  29% 262M/901M [00:01<00:03, 200MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  33% 294M/901M [00:01<00:02, 211MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  36% 325M/901M [00:02<00:02, 213MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  40% 357M/901M [00:02<00:02, 218MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  43% 388M/901M [00:02<00:02, 215MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  47% 419M/901M [00:02<00:02, 220MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  50% 451M/901M [00:02<00:01, 233MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  54% 482M/901M [00:02<00:01, 231MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  57% 514M/901M [00:02<00:01, 236MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  61% 545M/901M [00:03<00:01, 231MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  64% 577M/901M [00:03<00:01, 234MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  68% 608M/901M [00:03<00:01, 231MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  71% 640M/901M [00:03<00:01, 224MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  75% 671M/901M [00:03<00:01, 227MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  78% 703M/901M [00:03<00:00, 231MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  81% 734M/901M [00:03<00:00, 228MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  85% 765M/901M [00:04<00:00, 231MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  88% 797M/901M [00:04<00:00, 221MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  92% 828M/901M [00:04<00:00, 229MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  95% 860M/901M [00:04<00:00, 240MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt: 100% 901M/901M [00:04<00:00, 195MB/s]\n",
            "Fetching 12 files: 100% 12/12 [00:04<00:00,  2.49it/s]\n",
            "INFO:ChatTTS.core:use cuda:0\n",
            "/content/ChatTTS_colab/ChatTTS/core.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  vocos.load_state_dict(torch.load(vocos_ckpt_path))\n",
            "INFO:ChatTTS.core:vocos loaded.\n",
            "/content/ChatTTS_colab/ChatTTS/core.py:115: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  dvae.load_state_dict(torch.load(dvae_ckpt_path))\n",
            "INFO:ChatTTS.core:dvae loaded.\n",
            "/content/ChatTTS_colab/ChatTTS/core.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  gpt.load_state_dict(torch.load(gpt_ckpt_path))\n",
            "/content/ChatTTS_colab/ChatTTS/core.py:132: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.pretrain_models['spk_stat'] = torch.load(spk_stat_path).to(device)\n",
            "INFO:ChatTTS.core:gpt loaded.\n",
            "/content/ChatTTS_colab/ChatTTS/core.py:139: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  decoder.load_state_dict(torch.load(decoder_ckpt_path, map_location='cpu'))\n",
            "INFO:ChatTTS.core:decoder loaded.\n",
            "/content/ChatTTS_colab/ChatTTS/core.py:144: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  tokenizer = torch.load(tokenizer_path, map_location='cpu')\n",
            "INFO:ChatTTS.core:tokenizer loaded.\n",
            "INFO:ChatTTS.core:All initialized.\n",
            "INFO:httpx:HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://api.gradio.app/v3/tunnel-request \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://cdn-media.huggingface.co/frpc-gradio-0.3/frpc_linux_amd64 \"HTTP/1.1 200 OK\"\n",
            "* Running on public URL: https://76523d8b6e76434098.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            "[['æ—ç™½', 0], ['å¹´è½»å¥³æ€§', 0], ['ä¸­å¹´ç”·æ€§', 0]]\n",
            "[{'character': 'æ—ç™½', 'seed': 2222, 'speed': 3, 'oral': 0, 'laugh': 0, 'break': 2}, {'character': 'å¹´è½»å¥³æ€§', 'seed': 2, 'speed': 5, 'oral': 2, 'laugh': 0, 'break': 2}, {'character': 'ä¸­å¹´ç”·æ€§', 'seed': 2424, 'speed': 5, 'oral': 2, 'laugh': 0, 'break': 2}]\n",
            "{'æ—ç™½': {'character': 'æ—ç™½', 'seed': 2222, 'speed': 3, 'oral': 0, 'laugh': 0, 'break': 2}, 'å¹´è½»å¥³æ€§': {'character': 'å¹´è½»å¥³æ€§', 'seed': 2, 'speed': 5, 'oral': 2, 'laugh': 0, 'break': 2}, 'ä¸­å¹´ç”·æ€§': {'character': 'ä¸­å¹´ç”·æ€§', 'seed': 2424, 'speed': 5, 'oral': 2, 'laugh': 0, 'break': 2}}\n",
            "Building prefix dict from the default dictionary ...\n",
            "DEBUG:jieba:Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "DEBUG:jieba:Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.647 seconds.\n",
            "DEBUG:jieba:Loading model cost 0.647 seconds.\n",
            "Prefix dict has been built successfully.\n",
            "DEBUG:jieba:Prefix dict has been built successfully.\n",
            "seed=2222 t=['åœ¨ä¸€ä¸ªé£å’Œæ—¥ä¸½çš„ä¸‹åˆï¼Œå°çº¢å¸½å‡†å¤‡å»æ£®æ—é‡Œçœ‹æœ›å¥¹çš„å¥¶å¥¶ã€‚', 'å°çº¢å¸½è¯´', 'åœ¨æ£®æ—é‡Œï¼Œå°çº¢å¸½é‡åˆ°äº†ç‹¡çŒ¾çš„å¤§ç°ç‹¼ã€‚', 'å¤§ç°ç‹¼è¯´', 'å°çº¢å¸½å›ç­”'] c=æ—ç™½ s=3 r=[oral_0][laugh_0][break_2]\n",
            "speaker_type: seed\n",
            "Inferring audio for seed=2222:   0% 0/2 [00:00<?, ?steps/s]INFO:ChatTTS.core:All initialized.\n",
            "2025-03-10 12:06:14,282 WETEXT INFO found existing fst: /usr/local/lib/python3.11/dist-packages/tn/zh_tn_tagger.fst\n",
            "INFO:wetext-zh_normalizer:found existing fst: /usr/local/lib/python3.11/dist-packages/tn/zh_tn_tagger.fst\n",
            "2025-03-10 12:06:14,282 WETEXT INFO                     /usr/local/lib/python3.11/dist-packages/tn/zh_tn_verbalizer.fst\n",
            "INFO:wetext-zh_normalizer:                    /usr/local/lib/python3.11/dist-packages/tn/zh_tn_verbalizer.fst\n",
            "2025-03-10 12:06:14,283 WETEXT INFO skip building fst for zh_normalizer ...\n",
            "INFO:wetext-zh_normalizer:skip building fst for zh_normalizer ...\n",
            "INFO:ChatTTS.core:homophones_replacer loaded.\n",
            "Inferring audio for seed=2222:   0% 0/2 [00:00<?, ?steps/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2103, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1650, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 890, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/webui_mix.py\", line 870, in generate_script_audio\n",
            "    wavs = generate_audio_for_seed(chat, int(seed), texts, DEFAULT_BATCH_SIZE, speed,\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/tts_model.py\", line 110, in generate_audio_for_seed\n",
            "    wavs = chat.infer(batch, params_infer_code=_params_infer_code, params_refine_text=params_refine_text,\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/ChatTTS/core.py\", line 259, in infer\n",
            "    return next(res_gen)\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/ChatTTS/core.py\", line 187, in _infer\n",
            "    text_tokens = refine_text(\n",
            "                  ^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/ChatTTS/infer/api.py\", line 97, in refine_text\n",
            "    text_token = models['tokenizer'](text, return_tensors='pt', add_special_tokens=False, padding=True).to(device)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2868, in __call__\n",
            "    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2956, in _call_one\n",
            "    return self.batch_encode_plus(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 3149, in batch_encode_plus\n",
            "    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(\n",
            "                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2769, in _get_padding_truncation_strategies\n",
            "    if padding_strategy != PaddingStrategy.DO_NOT_PAD and (self.pad_token is None or self.pad_token_id < 0):\n",
            "                                                           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 1108, in __getattr__\n",
            "    raise AttributeError(f\"{self.__class__.__name__} has no attribute {key}\")\n",
            "AttributeError: BertTokenizerFast has no attribute pad_token\n",
            "[['æ—ç™½', 0], ['å¹´è½»å¥³æ€§', 0], ['ä¸­å¹´ç”·æ€§', 0]]\n",
            "[{'character': 'æ—ç™½', 'seed': 2222, 'speed': 3, 'oral': 0, 'laugh': 0, 'break': 2}, {'character': 'å¹´è½»å¥³æ€§', 'seed': 2, 'speed': 5, 'oral': 2, 'laugh': 0, 'break': 2}, {'character': 'ä¸­å¹´ç”·æ€§', 'seed': 2424, 'speed': 5, 'oral': 2, 'laugh': 0, 'break': 2}]\n",
            "{'æ—ç™½': {'character': 'æ—ç™½', 'seed': 2222, 'speed': 3, 'oral': 0, 'laugh': 0, 'break': 2}, 'å¹´è½»å¥³æ€§': {'character': 'å¹´è½»å¥³æ€§', 'seed': 2, 'speed': 5, 'oral': 2, 'laugh': 0, 'break': 2}, 'ä¸­å¹´ç”·æ€§': {'character': 'ä¸­å¹´ç”·æ€§', 'seed': 2424, 'speed': 5, 'oral': 2, 'laugh': 0, 'break': 2}}\n",
            "seed=2222 t=['åœ¨ä¸€ä¸ªé£å’Œæ—¥ä¸½çš„ä¸‹åˆï¼Œå°çº¢å¸½å‡†å¤‡å»æ£®æ—é‡Œçœ‹æœ›å¥¹çš„å¥¶å¥¶ã€‚', 'å°çº¢å¸½è¯´', 'åœ¨æ£®æ—é‡Œï¼Œå°çº¢å¸½é‡åˆ°äº†ç‹¡çŒ¾çš„å¤§ç°ç‹¼ã€‚', 'å¤§ç°ç‹¼è¯´', 'å°çº¢å¸½å›ç­”'] c=æ—ç™½ s=3 r=[oral_0][laugh_0][break_2]\n",
            "speaker_type: seed\n",
            "Inferring audio for seed=2222:   0% 0/2 [00:00<?, ?steps/s]INFO:ChatTTS.core:All initialized.\n",
            "Inferring audio for seed=2222:   0% 0/2 [00:00<?, ?steps/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2103, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1650, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 890, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/webui_mix.py\", line 870, in generate_script_audio\n",
            "    wavs = generate_audio_for_seed(chat, int(seed), texts, DEFAULT_BATCH_SIZE, speed,\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/tts_model.py\", line 110, in generate_audio_for_seed\n",
            "    wavs = chat.infer(batch, params_infer_code=_params_infer_code, params_refine_text=params_refine_text,\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/ChatTTS/core.py\", line 259, in infer\n",
            "    return next(res_gen)\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/ChatTTS/core.py\", line 187, in _infer\n",
            "    text_tokens = refine_text(\n",
            "                  ^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/ChatTTS/infer/api.py\", line 97, in refine_text\n",
            "    text_token = models['tokenizer'](text, return_tensors='pt', add_special_tokens=False, padding=True).to(device)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2868, in __call__\n",
            "    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2956, in _call_one\n",
            "    return self.batch_encode_plus(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 3149, in batch_encode_plus\n",
            "    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(\n",
            "                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2769, in _get_padding_truncation_strategies\n",
            "    if padding_strategy != PaddingStrategy.DO_NOT_PAD and (self.pad_token is None or self.pad_token_id < 0):\n",
            "                                                           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 1108, in __getattr__\n",
            "    raise AttributeError(f\"{self.__class__.__name__} has no attribute {key}\")\n",
            "AttributeError: BertTokenizerFast has no attribute pad_token\n",
            "[['æ—ç™½', 0], ['å¹´è½»å¥³æ€§', 0], ['ä¸­å¹´ç”·æ€§', 0]]\n",
            "[['æ—ç™½', 0], ['å¹´è½»å¥³æ€§', 0], ['ä¸­å¹´ç”·æ€§', 0]]\n",
            "[{'character': 'æ—ç™½', 'seed': 0, 'speed': 5, 'oral': 2, 'laugh': 0, 'break': 4}, {'character': 'å¹´è½»å¥³æ€§', 'seed': 0, 'speed': 5, 'oral': 2, 'laugh': 0, 'break': 4}, {'character': 'ä¸­å¹´ç”·æ€§', 'seed': 0, 'speed': 5, 'oral': 2, 'laugh': 0, 'break': 4}]\n",
            "{'æ—ç™½': {'character': 'æ—ç™½', 'seed': 0, 'speed': 5, 'oral': 2, 'laugh': 0, 'break': 4}, 'å¹´è½»å¥³æ€§': {'character': 'å¹´è½»å¥³æ€§', 'seed': 0, 'speed': 5, 'oral': 2, 'laugh': 0, 'break': 4}, 'ä¸­å¹´ç”·æ€§': {'character': 'ä¸­å¹´ç”·æ€§', 'seed': 0, 'speed': 5, 'oral': 2, 'laugh': 0, 'break': 4}}\n",
            "seed=0 t=['åœ¨ä¸€ä¸ªé£å’Œæ—¥ä¸½çš„ä¸‹åˆï¼Œå°çº¢å¸½å‡†å¤‡å»æ£®æ—é‡Œçœ‹æœ›å¥¹çš„å¥¶å¥¶ã€‚', 'å°çº¢å¸½è¯´', 'åœ¨æ£®æ—é‡Œï¼Œå°çº¢å¸½é‡åˆ°äº†ç‹¡çŒ¾çš„å¤§ç°ç‹¼ã€‚', 'å¤§ç°ç‹¼è¯´', 'å°çº¢å¸½å›ç­”'] c=æ—ç™½ s=5 r=[oral_2][laugh_0][break_4]\n",
            "speaker_type: seed\n",
            "Inferring audio for seed=2657:   0% 0/2 [00:00<?, ?steps/s]INFO:ChatTTS.core:All initialized.\n",
            "Inferring audio for seed=2657:   0% 0/2 [00:00<?, ?steps/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2103, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1650, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 890, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/webui_mix.py\", line 870, in generate_script_audio\n",
            "    wavs = generate_audio_for_seed(chat, int(seed), texts, DEFAULT_BATCH_SIZE, speed,\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/tts_model.py\", line 110, in generate_audio_for_seed\n",
            "    wavs = chat.infer(batch, params_infer_code=_params_infer_code, params_refine_text=params_refine_text,\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/ChatTTS/core.py\", line 259, in infer\n",
            "    return next(res_gen)\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/ChatTTS/core.py\", line 187, in _infer\n",
            "    text_tokens = refine_text(\n",
            "                  ^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/ChatTTS/infer/api.py\", line 97, in refine_text\n",
            "    text_token = models['tokenizer'](text, return_tensors='pt', add_special_tokens=False, padding=True).to(device)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2868, in __call__\n",
            "    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2956, in _call_one\n",
            "    return self.batch_encode_plus(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 3149, in batch_encode_plus\n",
            "    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(\n",
            "                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2769, in _get_padding_truncation_strategies\n",
            "    if padding_strategy != PaddingStrategy.DO_NOT_PAD and (self.pad_token is None or self.pad_token_id < 0):\n",
            "                                                           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 1108, in __getattr__\n",
            "    raise AttributeError(f\"{self.__class__.__name__} has no attribute {key}\")\n",
            "AttributeError: BertTokenizerFast has no attribute pad_token\n",
            "INFO:httpx:HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
            "ChatCompletion(id='4edebecd-b2e7-4d84-a025-bf29cadd4fc9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='æ•…äº‹æ–‡æœ¬:  \\n\"åœ¨ä¸€ä¸ªé£é›¨äº¤åŠ çš„å¤œæ™šï¼ŒèŠ±æœ¨å…°æ‰‹æŒé•¿å‰‘ï¼Œç‹¬è‡ªä¸€äººç«™åœ¨æ‚¬å´–è¾¹ã€‚å¥¹çš„ç›®å…‰åšå®šï¼Œä»¿ä½›åœ¨ç­‰å¾…ç€ä»€ä¹ˆã€‚çªç„¶ï¼Œå‘¨æ ‘äººä»é»‘æš—ä¸­èµ°å‡ºï¼Œæ‰‹æŒæŠ˜æ‰‡ï¼Œé¢å¸¦å¾®ç¬‘ã€‚èŠ±æœ¨å…°å†·å†·åœ°è¯´é“ï¼šâ€œå‘¨æ ‘äººï¼Œä½ ç»ˆäºæ¥äº†ã€‚â€å‘¨æ ‘äººå¾®å¾®ä¸€ç¬‘ï¼Œå›åº”é“ï¼šâ€œèŠ±æœ¨å…°ï¼Œä½ æœç„¶æ˜¯ä¸ªä¸ç®€å•çš„å¥³å­ã€‚â€\"\\n\\nè½¬æ¢åçš„JSONæ ¼å¼:  \\n```json\\n[\\n    {\"txt\": \"åœ¨ä¸€ä¸ªé£é›¨äº¤åŠ çš„å¤œæ™šï¼ŒèŠ±æœ¨å…°æ‰‹æŒé•¿å‰‘ï¼Œç‹¬è‡ªä¸€äººç«™åœ¨æ‚¬å´–è¾¹ã€‚å¥¹çš„ç›®å…‰åšå®šï¼Œä»¿ä½›åœ¨ç­‰å¾…ç€ä»€ä¹ˆã€‚\", \"character\": \"æ—ç™½\"},\\n    {\"txt\": \"çªç„¶ï¼Œå‘¨æ ‘äººä»é»‘æš—ä¸­èµ°å‡ºï¼Œæ‰‹æŒæŠ˜æ‰‡ï¼Œé¢å¸¦å¾®ç¬‘ã€‚\", \"character\": \"æ—ç™½\"},\\n    {\"txt\": \"å‘¨æ ‘äººï¼Œä½ ç»ˆäºæ¥äº†ã€‚\", \"character\": \"èŠ±æœ¨å…°\"},\\n    {\"txt\": \"èŠ±æœ¨å…°ï¼Œä½ æœç„¶æ˜¯ä¸ªä¸ç®€å•çš„å¥³å­ã€‚\", \"character\": \"å‘¨æ ‘äºº\"}\\n]\\n```', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1741608801, model='deepseek-chat', object='chat.completion', service_tier=None, system_fingerprint='fp_3a5770e1b4_prod0225', usage=CompletionUsage(completion_tokens=198, prompt_tokens=360, total_tokens=558, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0), prompt_cache_hit_tokens=0, prompt_cache_miss_tokens=360))\n",
            "INFO:httpx:HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
            "ChatCompletion(id='8e5df976-d16d-4464-bc98-acab99032095', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='ä»¥ä¸‹æ˜¯å°†ã€ŠèŠ±æœ¨å…°å¤§æˆ˜å‘¨æ ‘äººã€‹æ•…äº‹æ–‡æœ¬è½¬æ¢ä¸ºé€‚åˆèˆå°æˆ–å±å¹•çš„å‰§æœ¬æ ¼å¼ï¼Œå¹¶ä»¥JSONæ ¼å¼è¾“å‡ºçš„ç»“æœã€‚æ•…äº‹æ–‡æœ¬ç»è¿‡åˆ†è§£ï¼Œæ—ç™½å’Œè§’è‰²å¯¹è¯æ¸…æ™°ï¼Œç¬¦åˆè§’è‰²èº«ä»½ã€‚\\n\\n```json\\n[\\n    {\\n        \"txt\": \"åœ¨ä¸€ä¸ªé£é›¨äº¤åŠ çš„å¤œæ™šï¼Œæ±Ÿæ¹–ä¸Šæµä¼ ç€ä¸€ä¸ªä¼ è¯´ï¼šèŠ±æœ¨å…°ä¸å‘¨æ ‘äººå³å°†åœ¨åå±±ä¹‹å·…å±•å¼€ä¸€åœºæƒŠå¤©åŠ¨åœ°çš„å¯¹å†³ã€‚\",\\n        \"character\": \"æ—ç™½\"\\n    },\\n    {\\n        \"txt\": \"èŠ±æœ¨å…°ï¼Œä¸€ä½è‹±å§¿é£’çˆ½çš„å¥³ä¾ ï¼Œæ‰‹æŒé•¿å‰‘ï¼Œç›®å…‰å¦‚ç‚¬ã€‚å¥¹ç«™åœ¨åå±±ä¹‹å·…ï¼Œè¿é£è€Œç«‹ã€‚\",\\n        \"character\": \"æ—ç™½\"\\n    },\\n    {\\n        \"txt\": \"å‘¨æ ‘äººï¼Œä¸€ä½æ–‡é‡‡æ–ç„¶çš„ä¹¦ç”Ÿï¼Œæ‰‹æŒæŠ˜æ‰‡ï¼Œç¥æƒ…æ·¡ç„¶ã€‚ä»–ç¼“æ­¥èµ°ä¸Šå±±å·…ï¼Œä¸èŠ±æœ¨å…°å¯¹è§†ã€‚\",\\n        \"character\": \"æ—ç™½\"\\n    },\\n    {\\n        \"txt\": \"èŠ±æœ¨å…°å†·å†·åœ°è¯´é“\",\\n        \"character\": \"æ—ç™½\"\\n    },\\n    {\\n        \"txt\": \"å‘¨å…ˆç”Ÿï¼Œä»Šæ—¥ä¸€æˆ˜ï¼Œæ—¢åˆ†é«˜ä¸‹ï¼Œä¹Ÿå†³ç”Ÿæ­»ï¼\",\\n        \"character\": \"èŠ±æœ¨å…°\"\\n    },\\n    {\\n        \"txt\": \"å‘¨æ ‘äººå¾®å¾®ä¸€ç¬‘ï¼ŒæŠ˜æ‰‡è½»æ‘‡ï¼Œè¯´é“\",\\n        \"character\": \"æ—ç™½\"\\n    },\\n    {\\n        \"txt\": \"èŠ±å¥³ä¾ ï¼Œä½•å¿…å¦‚æ­¤ï¼Ÿæ±Ÿæ¹–æ©æ€¨ï¼Œä¸è¿‡æ˜¯ä¸€åœºè™šå¦„ã€‚ä¸å¦‚æˆ‘ä»¬åä¸‹æ¥ï¼Œå“èŒ¶è®ºé“ï¼Œå²‚ä¸å¿«å“‰ï¼Ÿ\",\\n        \"character\": \"å‘¨æ ‘äºº\"\\n    },\\n    {\\n        \"txt\": \"èŠ±æœ¨å…°å†·å“¼ä¸€å£°ï¼Œé•¿å‰‘å‡ºé˜ï¼Œå‰‘å…‰å¦‚è™¹ã€‚\",\\n        \"character\": \"æ—ç™½\"\\n    },\\n    {\\n        \"txt\": \"å‘¨å…ˆç”Ÿï¼Œä½ è‹¥ä¸æ•¢åº”æˆ˜ï¼Œä¾¿è®¤è¾“å§ï¼\",\\n        \"character\": \"èŠ±æœ¨å…°\"\\n    },\\n    {\\n        \"txt\": \"å‘¨æ ‘äººæ”¶èµ·æŠ˜æ‰‡ï¼Œç¥è‰²å‡é‡ã€‚ä»–ç¼“ç¼“ä»è¢–ä¸­å–å‡ºä¸€æ”¯æ¯›ç¬”ï¼Œè¯´é“\",\\n        \"character\": \"æ—ç™½\"\\n    },\\n    {\\n        \"txt\": \"æ—¢ç„¶å¦‚æ­¤ï¼Œå‘¨æŸä¾¿ä»¥ç¬”ä¸ºå‰‘ï¼Œé¢†æ•™èŠ±å¥³ä¾ çš„é«˜æ‹›ï¼\",\\n        \"character\": \"å‘¨æ ‘äºº\"\\n    },\\n    {\\n        \"txt\": \"ä¸¤äººå¯¹å³™ç‰‡åˆ»ï¼Œå¿½ç„¶é—´ï¼ŒèŠ±æœ¨å…°èº«å½¢ä¸€é—ªï¼Œé•¿å‰‘ç›´æŒ‡å‘¨æ ‘äººã€‚å‘¨æ ‘äººåˆ™ä»¥æ¯›ç¬”ä¸ºå‰‘ï¼Œæ‹›å¼é£˜é€¸ï¼Œä¸èŠ±æœ¨å…°æˆ˜åœ¨ä¸€å¤„ã€‚\",\\n        \"character\": \"æ—ç™½\"\\n    },\\n    {\\n        \"txt\": \"èŠ±æœ¨å…°çš„å‰‘æ³•å‡Œå‰ï¼Œæ‹›æ‹›è‡´å‘½ï¼›å‘¨æ ‘äººçš„ç¬”æ³•çµåŠ¨ï¼Œä»¥æŸ”å…‹åˆšã€‚ä¸¤äººä½ æ¥æˆ‘å¾€ï¼Œæˆ˜å¾—éš¾è§£éš¾åˆ†ã€‚\",\\n        \"character\": \"æ—ç™½\"\\n    },\\n    {\\n        \"txt\": \"èŠ±æœ¨å…°çªç„¶æ”¶å‰‘ï¼Œå†·å†·åœ°è¯´é“\",\\n        \"character\": \"æ—ç™½\"\\n    },\\n    {\\n        \"txt\": \"å‘¨å…ˆç”Ÿï¼Œä½ çš„ç¬”æ³•è™½å¦™ï¼Œå´å°‘äº†æ€ä¼ä¹‹æ°”ã€‚è¿™æ ·çš„æ­¦åŠŸï¼Œå¦‚ä½•èƒ½åœ¨æ±Ÿæ¹–ç«‹è¶³ï¼Ÿ\",\\n        \"character\": \"èŠ±æœ¨å…°\"\\n    },\\n    {\\n        \"txt\": \"å‘¨æ ‘äººå¾®å¾®ä¸€ç¬‘ï¼Œè¯´é“\",\\n        \"character\": \"æ—ç™½\"\\n    },\\n    {\\n        \"txt\": \"èŠ±å¥³ä¾ ï¼Œæ­¦åŠŸå¹¶éåªæœ‰æ€ä¼ã€‚ä»¥æ–‡ä¼šæ­¦ï¼Œä»¥æŸ”å…‹åˆšï¼Œæ‰æ˜¯çœŸæ­£çš„å¢ƒç•Œã€‚\",\\n        \"character\": \"å‘¨æ ‘äºº\"\\n    },\\n    {\\n        \"txt\": \"èŠ±æœ¨å…°æ²‰é»˜ç‰‡åˆ»ï¼Œå¿½ç„¶æ”¶èµ·é•¿å‰‘ï¼Œè¯´é“\",\\n        \"character\": \"æ—ç™½\"\\n    },\\n    {\\n        \"txt\": \"å‘¨å…ˆç”Ÿï¼Œä»Šæ—¥ä¸€æˆ˜ï¼Œæ˜¯æˆ‘è¾“äº†ã€‚ä½ çš„å¢ƒç•Œï¼Œæˆ‘æœ›å°˜è«åŠã€‚\",\\n        \"character\": \"èŠ±æœ¨å…°\"\\n    },\\n    {\\n        \"txt\": \"å‘¨æ ‘äººæ”¶èµ·æ¯›ç¬”ï¼Œæ‹±æ‰‹è¯´é“\",\\n        \"character\": \"æ—ç™½\"\\n    },\\n    {\\n        \"txt\": \"èŠ±å¥³ä¾ è¿‡è°¦äº†ã€‚æ±Ÿæ¹–è·¯è¿œï¼Œæ„¿æˆ‘ä»¬åä¼šæœ‰æœŸã€‚\",\\n        \"character\": \"å‘¨æ ‘äºº\"\\n    },\\n    {\\n        \"txt\": \"ä¸¤äººç›¸è§†ä¸€ç¬‘ï¼Œå„è‡ªç¦»å»ã€‚åå±±ä¹‹å·…ï¼Œé£é›¨æ¸æ­‡ï¼Œåªç•™ä¸‹ä¸€æ®µä¼ å¥‡ã€‚\",\\n        \"character\": \"æ—ç™½\"\\n    }\\n]\\n```\\n\\n### è¯´æ˜ï¼š\\n1. **æ—ç™½**ï¼šç”¨äºæè¿°åœºæ™¯ã€åŠ¨ä½œå’ŒèƒŒæ™¯ä¿¡æ¯ï¼Œå¸®åŠ©è§‚ä¼—ç†è§£æ•…äº‹å‘å±•ã€‚\\n2. **è§’è‰²å¯¹è¯**ï¼šæ ¹æ®è§’è‰²èº«ä»½åˆ†é…å¯¹è¯ï¼ŒèŠ±æœ¨å…°ä¸ºâ€œèŠ±æœ¨å…°â€ï¼Œå‘¨æ ‘äººä¸ºâ€œå‘¨æ ‘äººâ€ã€‚\\n3. **JSONæ ¼å¼**ï¼šæ¯ä¸ªæ®µè½åŒ…å«`txt`ï¼ˆæ–‡æœ¬å†…å®¹ï¼‰å’Œ`character`ï¼ˆè§’è‰²èº«ä»½ï¼‰ï¼Œä¾¿äºè§£æå’Œä½¿ç”¨ã€‚\\n\\nå¸Œæœ›è¿™ä»½å‰§æœ¬èƒ½æ»¡è¶³æ‚¨çš„éœ€æ±‚ï¼', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1741608828, model='deepseek-chat', object='chat.completion', service_tier=None, system_fingerprint='fp_3a5770e1b4_prod0225', usage=CompletionUsage(completion_tokens=942, prompt_tokens=364, total_tokens=1306, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=320), prompt_cache_hit_tokens=320, prompt_cache_miss_tokens=44))\n",
            "[['æ—ç™½', 0], ['èŠ±æœ¨å…°', 0], ['å‘¨æ ‘äºº', 0]]\n",
            "[{'character': 'æ—ç™½', 'seed': 0, 'speed': 5, 'oral': 2, 'laugh': 0, 'break': 4}, {'character': 'å¹´è½»å¥³æ€§', 'seed': 0, 'speed': 5, 'oral': 2, 'laugh': 0, 'break': 4}, {'character': 'ä¸­å¹´ç”·æ€§', 'seed': 0, 'speed': 5, 'oral': 2, 'laugh': 0, 'break': 4}]\n",
            "[['æ—ç™½', 0], ['èŠ±æœ¨å…°', 0], ['å‘¨æ ‘äºº', 0]]\n",
            "[['æ—ç™½', 0], ['èŠ±æœ¨å…°', 0], ['å‘¨æ ‘äºº', 0]]\n",
            "[{'character': 'æ—ç™½', 'seed': 0, 'speed': 5, 'oral': 2, 'laugh': 0, 'break': 4}, {'character': 'èŠ±æœ¨å…°', 'seed': 0, 'speed': 5, 'oral': 2, 'laugh': 0, 'break': 4}, {'character': 'å‘¨æ ‘äºº', 'seed': 0, 'speed': 5, 'oral': 2, 'laugh': 0, 'break': 4}]\n",
            "{'æ—ç™½': {'character': 'æ—ç™½', 'seed': 0, 'speed': 5, 'oral': 2, 'laugh': 0, 'break': 4}, 'èŠ±æœ¨å…°': {'character': 'èŠ±æœ¨å…°', 'seed': 0, 'speed': 5, 'oral': 2, 'laugh': 0, 'break': 4}, 'å‘¨æ ‘äºº': {'character': 'å‘¨æ ‘äºº', 'seed': 0, 'speed': 5, 'oral': 2, 'laugh': 0, 'break': 4}}\n",
            "seed=0 t=['åœ¨ä¸€ä¸ªé£é›¨äº¤åŠ çš„å¤œæ™šï¼Œæ±Ÿæ¹–ä¸Šæµä¼ ç€ä¸€ä¸ªä¼ è¯´ï¼ŒèŠ±æœ¨å…°ä¸å‘¨æ ‘äººå³å°†åœ¨åå±±ä¹‹å·…å±•å¼€ä¸€åœºæƒŠå¤©åŠ¨åœ°çš„å¯¹å†³ã€‚', 'èŠ±æœ¨å…°ï¼Œä¸€ä½è‹±å§¿é£’çˆ½çš„å¥³ä¾ ï¼Œæ‰‹æŒé•¿å‰‘ï¼Œç›®å…‰å¦‚ç‚¬ã€‚å¥¹ç«™åœ¨åå±±ä¹‹å·…ï¼Œè¿é£è€Œç«‹ã€‚', 'å‘¨æ ‘äººï¼Œä¸€ä½æ–‡é‡‡æ–ç„¶çš„ä¹¦ç”Ÿï¼Œæ‰‹æŒæŠ˜æ‰‡ï¼Œç¥æƒ…æ·¡ç„¶ã€‚ä»–ç¼“æ­¥èµ°ä¸Šå±±å·…ï¼Œä¸èŠ±æœ¨å…°å¯¹è§†ã€‚', 'èŠ±æœ¨å…°å†·å†·åœ°è¯´é“', 'å‘¨æ ‘äººå¾®å¾®ä¸€ç¬‘ï¼ŒæŠ˜æ‰‡è½»æ‘‡ï¼Œè¯´é“'] c=æ—ç™½ s=5 r=[oral_2][laugh_0][break_4]\n",
            "speaker_type: seed\n",
            "Inferring audio for seed=5099:   0% 0/2 [00:00<?, ?steps/s]INFO:ChatTTS.core:All initialized.\n",
            "Inferring audio for seed=5099:   0% 0/2 [00:00<?, ?steps/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2103, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1650, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 890, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/webui_mix.py\", line 870, in generate_script_audio\n",
            "    wavs = generate_audio_for_seed(chat, int(seed), texts, DEFAULT_BATCH_SIZE, speed,\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/tts_model.py\", line 110, in generate_audio_for_seed\n",
            "    wavs = chat.infer(batch, params_infer_code=_params_infer_code, params_refine_text=params_refine_text,\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/ChatTTS/core.py\", line 259, in infer\n",
            "    return next(res_gen)\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/ChatTTS/core.py\", line 187, in _infer\n",
            "    text_tokens = refine_text(\n",
            "                  ^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/ChatTTS/infer/api.py\", line 97, in refine_text\n",
            "    text_token = models['tokenizer'](text, return_tensors='pt', add_special_tokens=False, padding=True).to(device)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2868, in __call__\n",
            "    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2956, in _call_one\n",
            "    return self.batch_encode_plus(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 3149, in batch_encode_plus\n",
            "    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(\n",
            "                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2769, in _get_padding_truncation_strategies\n",
            "    if padding_strategy != PaddingStrategy.DO_NOT_PAD and (self.pad_token is None or self.pad_token_id < 0):\n",
            "                                                           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 1108, in __getattr__\n",
            "    raise AttributeError(f\"{self.__class__.__name__} has no attribute {key}\")\n",
            "AttributeError: BertTokenizerFast has no attribute pad_token\n",
            "['å››å·ç¾é£Ÿç¡®å®ä»¥è¾£é—»åï¼Œä½†ä¹Ÿæœ‰ä¸è¾£çš„é€‰æ‹©ã€‚æ¯”å¦‚ç”œæ°´é¢ã€èµ–æ±¤åœ†ã€è›‹çƒ˜ç³•ã€å¶å„¿ç²‘ç­‰ï¼Œè¿™äº›å°åƒå£å‘³æ¸©å’Œï¼Œç”œè€Œä¸è…»ï¼Œä¹Ÿå¾ˆå—æ¬¢è¿ã€‚', 'æˆ‘æ˜¯ä¸€ä¸ªå……æ»¡æ´»åŠ›çš„äººï¼Œå–œæ¬¢è¿åŠ¨ï¼Œå–œæ¬¢æ—…è¡Œï¼Œå–œæ¬¢å°è¯•æ–°é²œäº‹ç‰©ã€‚æˆ‘å–œæ¬¢æŒ‘æˆ˜è‡ªå·±ï¼Œä¸æ–­çªç ´è‡ªå·±çš„æé™ï¼Œè®©è‡ªå·±å˜å¾—æ›´åŠ å¼ºå¤§ã€‚', 'ç½—æ£®å®£å¸ƒå°†äº7æœˆ24æ—¥é€€å¸‚ï¼Œåœ¨åé—¨åº—è¶…6000å®¶']\n",
            "speaker_type: seed\n",
            "Inferring audio for seed=9378:   0% 0/3 [00:00<?, ?steps/s]INFO:ChatTTS.core:All initialized.\n",
            "Inferring audio for seed=9378:   0% 0/3 [00:00<?, ?steps/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2103, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1650, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 890, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/webui_mix.py\", line 212, in audio_interface\n",
            "    seeds = generate_seeds(num_seeds, texts, progress.tqdm)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/webui_mix.py\", line 139, in generate_seeds\n",
            "    filename = generate_audio_for_seed(chat, seed, texts, 1, 5, \"[oral_2][laugh_0][break_4]\", None, 0.3, 0.7, 20)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/tts_model.py\", line 110, in generate_audio_for_seed\n",
            "    wavs = chat.infer(batch, params_infer_code=_params_infer_code, params_refine_text=params_refine_text,\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/ChatTTS/core.py\", line 259, in infer\n",
            "    return next(res_gen)\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/ChatTTS/core.py\", line 187, in _infer\n",
            "    text_tokens = refine_text(\n",
            "                  ^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/ChatTTS/infer/api.py\", line 97, in refine_text\n",
            "    text_token = models['tokenizer'](text, return_tensors='pt', add_special_tokens=False, padding=True).to(device)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2868, in __call__\n",
            "    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2956, in _call_one\n",
            "    return self.batch_encode_plus(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 3149, in batch_encode_plus\n",
            "    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(\n",
            "                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2769, in _get_padding_truncation_strategies\n",
            "    if padding_strategy != PaddingStrategy.DO_NOT_PAD and (self.pad_token is None or self.pad_token_id < 0):\n",
            "                                                           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 1108, in __getattr__\n",
            "    raise AttributeError(f\"{self.__class__.__name__} has no attribute {key}\")\n",
            "AttributeError: BertTokenizerFast has no attribute pad_token\n",
            "['å››å·ç¾é£Ÿç¡®å®ä»¥è¾£é—»åï¼Œä½†ä¹Ÿæœ‰ä¸è¾£çš„é€‰æ‹©ã€‚']\n",
            "speaker_type: seed\n",
            "Inferring audio for seed=2464:   0% 0/1 [00:00<?, ?steps/s]INFO:ChatTTS.core:All initialized.\n",
            "Inferring audio for seed=2464:   0% 0/1 [00:00<?, ?steps/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2103, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1650, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 890, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/webui_mix.py\", line 212, in audio_interface\n",
            "    seeds = generate_seeds(num_seeds, texts, progress.tqdm)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/webui_mix.py\", line 139, in generate_seeds\n",
            "    filename = generate_audio_for_seed(chat, seed, texts, 1, 5, \"[oral_2][laugh_0][break_4]\", None, 0.3, 0.7, 20)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/tts_model.py\", line 110, in generate_audio_for_seed\n",
            "    wavs = chat.infer(batch, params_infer_code=_params_infer_code, params_refine_text=params_refine_text,\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/ChatTTS/core.py\", line 259, in infer\n",
            "    return next(res_gen)\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/ChatTTS/core.py\", line 187, in _infer\n",
            "    text_tokens = refine_text(\n",
            "                  ^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/ChatTTS/infer/api.py\", line 97, in refine_text\n",
            "    text_token = models['tokenizer'](text, return_tensors='pt', add_special_tokens=False, padding=True).to(device)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2868, in __call__\n",
            "    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2956, in _call_one\n",
            "    return self.batch_encode_plus(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 3149, in batch_encode_plus\n",
            "    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(\n",
            "                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2769, in _get_padding_truncation_strategies\n",
            "    if padding_strategy != PaddingStrategy.DO_NOT_PAD and (self.pad_token is None or self.pad_token_id < 0):\n",
            "                                                           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 1108, in __getattr__\n",
            "    raise AttributeError(f\"{self.__class__.__name__} has no attribute {key}\")\n",
            "AttributeError: BertTokenizerFast has no attribute pad_token\n",
            "k=3, audios=10\n",
            "['å››å·ç¾é£Ÿç¡®å®ä»¥è¾£é—»åï¼Œä½†ä¹Ÿæœ‰ä¸è¾£çš„é€‰æ‹©ã€‚']\n",
            "speaker_type: seed\n",
            "Inferring audio for seed=826:   0% 0/1 [00:00<?, ?steps/s]INFO:ChatTTS.core:All initialized.\n",
            "Inferring audio for seed=826:   0% 0/1 [00:00<?, ?steps/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2103, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1650, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 890, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/webui_mix.py\", line 212, in audio_interface\n",
            "    seeds = generate_seeds(num_seeds, texts, progress.tqdm)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/webui_mix.py\", line 139, in generate_seeds\n",
            "    filename = generate_audio_for_seed(chat, seed, texts, 1, 5, \"[oral_2][laugh_0][break_4]\", None, 0.3, 0.7, 20)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/tts_model.py\", line 110, in generate_audio_for_seed\n",
            "    wavs = chat.infer(batch, params_infer_code=_params_infer_code, params_refine_text=params_refine_text,\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/ChatTTS/core.py\", line 259, in infer\n",
            "    return next(res_gen)\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/ChatTTS/core.py\", line 187, in _infer\n",
            "    text_tokens = refine_text(\n",
            "                  ^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/ChatTTS/infer/api.py\", line 97, in refine_text\n",
            "    text_token = models['tokenizer'](text, return_tensors='pt', add_special_tokens=False, padding=True).to(device)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2868, in __call__\n",
            "    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2956, in _call_one\n",
            "    return self.batch_encode_plus(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 3149, in batch_encode_plus\n",
            "    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(\n",
            "                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2769, in _get_padding_truncation_strategies\n",
            "    if padding_strategy != PaddingStrategy.DO_NOT_PAD and (self.pad_token is None or self.pad_token_id < 0):\n",
            "                                                           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 1108, in __getattr__\n",
            "    raise AttributeError(f\"{self.__class__.__name__} has no attribute {key}\")\n",
            "AttributeError: BertTokenizerFast has no attribute pad_token\n"
          ]
        }
      ]
    }
  ]
}